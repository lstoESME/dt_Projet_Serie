{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup #Pull data out of HTML and XML.\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_rank_serie = 'https://www.imdb.com/chart/toptv/'\n",
    "url_imdb_base = 'https://www.imdb.com'\n",
    "url_serie_ = f'?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=12230b0e-0e00-43ed-9e59-8d5353703cce&pf_rd_r=BFQY8EMES4H7BK35D10R&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=toptv&ref_=chttvtp_tt_'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_from_link(page_link):\n",
    "    '''\n",
    "        Get HTML from web page and parse it.\n",
    "\n",
    "        :param page_link: link of the webpage we want to scrap\n",
    "        :type page_link: string\n",
    "        :return: BeautifulSoup object (HTML parsed)\n",
    "        :rtype: bs4.BeautifulSoup\n",
    "    '''\n",
    "\n",
    "    response = requests.get(page_link)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_all = get_html_from_link(url_rank_serie)\n",
    "#print(html_all.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_to_serie(root_html):\n",
    "\n",
    "    \"\"\"\n",
    "    This function extract the link to acces the series information page.\n",
    "    \n",
    "    :param root_html: BeautifulSoup Element that contains all books links.\n",
    "    :type book_html: bs4.BeautifulSoup.\n",
    "    :return: list of all serie links in the page.\n",
    "    :rtype: list(str).\n",
    "    \"\"\"\n",
    "    serie_links = []\n",
    "    reg = re.compile('/title/+')\n",
    "    for elem in root_html.find_all('td', {'class':'titleColumn'}):\n",
    "        for elements in elem.find_all('a', {'href' : reg}):\n",
    "            attribut = elements[\"href\"]\n",
    "            serie_links.append(attribut)\n",
    "    #len(serie_links)\n",
    "    return(serie_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_links=get_link_to_serie(html_all)\n",
    "#serie_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_serie(serie_html):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return series informations\n",
    "    \n",
    "    :param serie_html: BeautifulSoup element that contains serie infos.\n",
    "    :type serie_html: bs4.element.Tag.\n",
    "    :return:\n",
    "            - serie_title: tile of the TV serie.\n",
    "            - serie_genre: genre-s of the TV serie.\n",
    "            - serie_nb_season: number of season of the serie.\n",
    "            - serie_nb_episode: number of episode of the serie.\n",
    "            - serie_type: the serie can be TV Mini-Series or TV Series.\n",
    "            - serie_actors : actors who play in the TV serie.\n",
    "            - serie_creator : creator-s of the TV serie\n",
    "            - serie_origin: origins/country of the TV serie.\n",
    "            - serie_language: speaking language of the TV serie.\n",
    "            - serie_certification : certificate of the TV serie (Tous public, 12, 16...).\n",
    "            - serie_rating: rating of the TV serie.\n",
    "    :rtype: tuple(string, list(str), string, string, string, list(str), list(str), list(str), string, string, string)\n",
    "    \"\"\"\n",
    "    \n",
    "    serie_title = serie_html.find('h1').text.strip()\n",
    "    \n",
    "    serie_genre=[]\n",
    "    reg_search = re.compile('/search/title+')\n",
    "    for div in serie_html.find_all(\"div\", {\"class\":\"see-more inline canwrap\"}):\n",
    "        for a in div.find_all(\"a\", {\"href\": reg_search}):\n",
    "            genre = a.text\n",
    "            serie_genre.append(genre)\n",
    "            \n",
    "            \n",
    "    nb_season=[]\n",
    "    reg_season = re.compile('/title/')\n",
    "    for div in serie_html.find_all(\"div\", {\"class\":\"seasons-and-year-nav\"}):\n",
    "        for c in div.find_all(\"a\", {\"href\": reg_season}):\n",
    "                season_not_filtered = c.text\n",
    "                nb_season.append(season_not_filtered)\n",
    "                serie_nb_season = \"\"\n",
    "                if nb_season != 1:\n",
    "                        serie_nb_season = nb_season[0]\n",
    "                        \n",
    "                        \n",
    "    serie_nb_episode=serie_html.find('span', {'class':'bp_sub_heading'}).text\n",
    "    \n",
    "    \n",
    "    reg = re.compile('/title/+')\n",
    "    serie_type = serie_html.find(\"a\", {\"href\": reg, \"title\":\"See more release dates\"}).text\n",
    "    \n",
    "    \n",
    "    serie_actors=[]\n",
    "    reg_name = re.compile('/name/nm+')\n",
    "    for div in serie_html.find_all(\"div\", {\"class\":\"article\", \"id\":\"titleCast\"}):\n",
    "        for a in div.find_all(\"a\", {\"href\": reg_name}):\n",
    "            actors = a.text\n",
    "            if actors != '':\n",
    "                serie_actors.append(actors)\n",
    "                \n",
    "                \n",
    "    serie_creators=[]\n",
    "    for div in serie_html.find_all(\"div\", {\"class\":\"credit_summary_item\"}):\n",
    "        creators = \"\"\n",
    "        if div.find(\"h4\", {\"class\":\"inline\"}).text == \"Creator:\":\n",
    "            for c in div.find_all(\"a\", {\"href\": reg_name}):\n",
    "                creators = c.text\n",
    "                serie_creators.append(creators)\n",
    "        elif div.find(\"h4\", {\"class\":\"inline\"}).text == \"Creators:\":\n",
    "            for c in div.find_all(\"a\", {\"href\": reg_name}):\n",
    "                creators = c.text\n",
    "                serie_creators.append(creators)\n",
    "                \n",
    "    \n",
    "    serie_origin=[]\n",
    "    for div in serie_html.find_all(\"div\", {\"class\":\"txt-block\"}):\n",
    "        for h in div.find_all(\"h4\", {\"class\":\"inline\"}):\n",
    "            country = \"\"\n",
    "            if h.text == \"Country:\":\n",
    "                for a in div.find_all(\"a\", {\"href\": reg_search}):\n",
    "                    country = a.text\n",
    "                    serie_origin.append(country)\n",
    "    \n",
    "    serie_language = \"\"\n",
    "    for div in serie_html.find_all(\"div\", {\"class\":\"txt-block\"}):\n",
    "        for h in div.find_all(\"h4\", {\"class\":\"inline\"}):\n",
    "            if h.text == \"Language:\":\n",
    "                for a in div.find_all(\"a\", {\"href\": reg_search}):\n",
    "                    serie_language = a.text\n",
    "                    \n",
    "                    \n",
    "    \n",
    "    certif =[]\n",
    "    serie_certification = \"\"\n",
    "    certificate_not_filtered = \"\"\n",
    "    for div in serie_html.find_all(\"div\", {\"class\":\"txt-block\"}):\n",
    "        for h in div.find_all(\"h4\", {\"class\":\"inline\"}):\n",
    "            if h.text == \"Certificate:\":\n",
    "                for s in div.find_all(\"span\"):\n",
    "                    certificate_not_filtered = s.text\n",
    "                    certif.append(certificate_not_filtered)\n",
    "                    if len(certif) != 1:\n",
    "                        serie_certification = certif[0]\n",
    "                        \n",
    "                        \n",
    "    serie_rating = serie_html.find('span', {'itemprop':'ratingValue'}).text\n",
    "                        \n",
    "    \n",
    "    return(serie_title, serie_genre, serie_nb_season, serie_nb_episode, serie_type, serie_actors, serie_creators, serie_origin, serie_language, serie_certification,  serie_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_serie_storyline(serie_html):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return series storyline.\n",
    "    \n",
    "    :param serie_html: BeautifulSoup element that contains serie infos.\n",
    "    :type serie_html: bs4.element.Tag.\n",
    "    :return: storyline of the TV series.\n",
    "    :rtype: tuple(string)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    for div in serie_html.find_all(\"div\", {\"id\":\"titleStoryLine\"}):\n",
    "        for story in div.find_all(\"div\", {\"class\":\"inline canwrap\"}):\n",
    "            storyline = story.find(\"span\").text\n",
    "    \n",
    "    return(storyline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop on the first 100 serie links to get informations.\n",
    "\n",
    "The list start at rank 0 : the first film with classement rank 1 on IMDb starts at rank 0 in the list. The classement rank is set at n + 1 (0 + 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time # ~4min\n",
    "\n",
    "serie_details = []\n",
    "\n",
    "#Initiate the rank number.\n",
    "rank_number = 0\n",
    "\n",
    "for n in range(len(serie_links)-150):\n",
    "    \n",
    "    rank_number = n + 1\n",
    "    # Add rank_number at the en of the url.\n",
    "    url_serie_rank = url_serie_ + str(rank_number)\n",
    "    \n",
    "    # Get the entire url of the page that contains serie informations.\n",
    "    link_serie = url_imdb_base + serie_links[n] + url_serie_rank\n",
    "    #print(link_serie) \n",
    "    \n",
    "    html = get_html_from_link(link_serie)\n",
    "    \n",
    "    # Apply get_info_serie function to return every link informations.\n",
    "    info = get_info_serie(html)\n",
    "    # Add rank.\n",
    "    info = (rank_number,) + info\n",
    "    \n",
    "    # Info contains tuples : add them to a list.\n",
    "    serie_details.append(info)\n",
    "    \n",
    "    print(rank_number)\n",
    "    #print(serie_details)\n",
    "    \n",
    "#print(serie_details)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des storylines pour le NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time # ~3min30\n",
    "\n",
    "serie_resume = []\n",
    "\n",
    "#Initiate the rank number.\n",
    "rank_number = 0\n",
    "\n",
    "for n in range(len(serie_links)-150):\n",
    "    \n",
    "    rank_number = n + 1\n",
    "    # Add rank_number at the en of the url.\n",
    "    url_serie_rank = url_serie_ + str(rank_number)\n",
    "    \n",
    "    # Get the entire url of the page that contains serie informations.\n",
    "    link_serie = url_imdb_base + serie_links[n] + url_serie_rank\n",
    "    #print(link_serie) \n",
    "    \n",
    "    html_story = get_html_from_link(link_serie)\n",
    "    \n",
    "    # Apply get_info_storyline function to return every storyline.\n",
    "    serie_storyline = get_serie_storyline(html_story)\n",
    "    \n",
    "    serie_resume.append(serie_storyline)\n",
    "\n",
    "    \n",
    "    print(rank_number)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
     ]
    }
   ],
   "source": [
    "#Get list of rank numbers to insert into dataframe.\n",
    "\n",
    "rank_number = 0\n",
    "rank=[]\n",
    "\n",
    "for n in range(len(serie_links)-150):\n",
    "    \n",
    "    rank_number = n + 1\n",
    "    \n",
    "    rank.append(rank_number)\n",
    "    \n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "url_test = url_imdb_base + serie_links[3] + url_serie_ + str(4)\n",
    "#print(url_test)\n",
    "cast = get_html_from_link(url_test)\n",
    "#print(type(cast))\n",
    "\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put de data into a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the data from the list of tuple into a dataframe df_serie.\n",
    "Then, export the dataframe to a csv file to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Number_of_season</th>\n",
       "      <th>Number_of_episodes</th>\n",
       "      <th>Type</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Creators</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Language</th>\n",
       "      <th>Certification</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Planet Earth II</td>\n",
       "      <td>[ Documentary]</td>\n",
       "      <td>1</td>\n",
       "      <td>6 episodes</td>\n",
       "      <td>TV Mini-Series (2016)\\n</td>\n",
       "      <td>[ David Attenborough\\n]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[UK]</td>\n",
       "      <td>English</td>\n",
       "      <td></td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Planète Terre</td>\n",
       "      <td>[ Documentary]</td>\n",
       "      <td>1</td>\n",
       "      <td>11 episodes</td>\n",
       "      <td>TV Mini-Series (2006)\\n</td>\n",
       "      <td>[ David Attenborough\\n,  Sigourney Weaver\\n,  ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[UK]</td>\n",
       "      <td>English</td>\n",
       "      <td>Tous publics</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Frères d'armes</td>\n",
       "      <td>[ Action,  Drama,  History,  War]</td>\n",
       "      <td>1</td>\n",
       "      <td>10 episodes</td>\n",
       "      <td>TV Mini-Series (2001)\\n</td>\n",
       "      <td>[ Scott Grimes\\n,  Damian Lewis\\n,  Ron Living...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[USA, UK]</td>\n",
       "      <td>Lithuanian</td>\n",
       "      <td>Tous publics</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>[ Crime,  Drama,  Thriller]</td>\n",
       "      <td>5</td>\n",
       "      <td>62 episodes</td>\n",
       "      <td>TV Series (2008–2013)\\n</td>\n",
       "      <td>[ Bryan Cranston\\n,  Anna Gunn\\n,  Aaron Paul\\...</td>\n",
       "      <td>[Vince Gilligan]</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Tous publics</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chernobyl</td>\n",
       "      <td>[ Drama,  History,  Thriller]</td>\n",
       "      <td>1</td>\n",
       "      <td>5 episodes</td>\n",
       "      <td>TV Mini-Series (2019)\\n</td>\n",
       "      <td>[ Jessie Buckley\\n,  Jared Harris\\n,  Stellan ...</td>\n",
       "      <td>[Craig Mazin]</td>\n",
       "      <td>[USA, UK]</td>\n",
       "      <td>English</td>\n",
       "      <td>12</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>The Thick of It</td>\n",
       "      <td>[ Comedy]</td>\n",
       "      <td>4</td>\n",
       "      <td>24 episodes</td>\n",
       "      <td>TV Series (2005–2012)\\n</td>\n",
       "      <td>[ Chris Addison\\n,  James Smith\\n,  Peter Capa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[UK]</td>\n",
       "      <td>English</td>\n",
       "      <td></td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Demon Slayer</td>\n",
       "      <td>[ Animation,  Action,  Fantasy,  Thriller]</td>\n",
       "      <td>1</td>\n",
       "      <td>27 episodes</td>\n",
       "      <td>TV Series (2019– )\\n</td>\n",
       "      <td>[ Natsuki Hanae\\n,  Zach Aguilar\\n,  Abby Trot...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Japan]</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Tous publics avec avertissement</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>The Promised Neverland</td>\n",
       "      <td>[ Animation,  Fantasy,  Horror,  Mystery,  Sci...</td>\n",
       "      <td>2</td>\n",
       "      <td>13 episodes</td>\n",
       "      <td>TV Series (2019– )\\n</td>\n",
       "      <td>[ Sumire Morohoshi\\n,  Maaya Uchida\\n,  Mariya...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Japan]</td>\n",
       "      <td>Japanese</td>\n",
       "      <td></td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>South Park</td>\n",
       "      <td>[ Animation,  Comedy]</td>\n",
       "      <td>24</td>\n",
       "      <td>309 episodes</td>\n",
       "      <td>TV Series (1997– )\\n</td>\n",
       "      <td>[ Trey Parker\\n,  Matt Stone\\n,  Mona Marshall...</td>\n",
       "      <td>[Trey Parker, Matt Stone, Brian Graden]</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>English</td>\n",
       "      <td>16</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Les Simpson</td>\n",
       "      <td>[ Animation,  Comedy]</td>\n",
       "      <td>32</td>\n",
       "      <td>684 episodes</td>\n",
       "      <td>TV Series (1989– )\\n</td>\n",
       "      <td>[ Dan Castellaneta\\n,  Nancy Cartwright\\n,  Ha...</td>\n",
       "      <td>[James L. Brooks, Matt Groening, Sam Simon]</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>Czech</td>\n",
       "      <td>Tous publics</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                   Title  \\\n",
       "0      1         Planet Earth II   \n",
       "1      2           Planète Terre   \n",
       "2      3          Frères d'armes   \n",
       "3      4            Breaking Bad   \n",
       "4      5               Chernobyl   \n",
       "..   ...                     ...   \n",
       "95    96         The Thick of It   \n",
       "96    97            Demon Slayer   \n",
       "97    98  The Promised Neverland   \n",
       "98    99              South Park   \n",
       "99   100             Les Simpson   \n",
       "\n",
       "                                                Genre Number_of_season  \\\n",
       "0                                      [ Documentary]                1   \n",
       "1                                      [ Documentary]                1   \n",
       "2                   [ Action,  Drama,  History,  War]                1   \n",
       "3                         [ Crime,  Drama,  Thriller]                5   \n",
       "4                       [ Drama,  History,  Thriller]                1   \n",
       "..                                                ...              ...   \n",
       "95                                          [ Comedy]                4   \n",
       "96         [ Animation,  Action,  Fantasy,  Thriller]                1   \n",
       "97  [ Animation,  Fantasy,  Horror,  Mystery,  Sci...                2   \n",
       "98                              [ Animation,  Comedy]               24   \n",
       "99                              [ Animation,  Comedy]               32   \n",
       "\n",
       "   Number_of_episodes                     Type  \\\n",
       "0          6 episodes  TV Mini-Series (2016)\\n   \n",
       "1         11 episodes  TV Mini-Series (2006)\\n   \n",
       "2         10 episodes  TV Mini-Series (2001)\\n   \n",
       "3         62 episodes  TV Series (2008–2013)\\n   \n",
       "4          5 episodes  TV Mini-Series (2019)\\n   \n",
       "..                ...                      ...   \n",
       "95        24 episodes  TV Series (2005–2012)\\n   \n",
       "96        27 episodes     TV Series (2019– )\\n   \n",
       "97        13 episodes     TV Series (2019– )\\n   \n",
       "98       309 episodes     TV Series (1997– )\\n   \n",
       "99       684 episodes     TV Series (1989– )\\n   \n",
       "\n",
       "                                               Actors  \\\n",
       "0                             [ David Attenborough\\n]   \n",
       "1   [ David Attenborough\\n,  Sigourney Weaver\\n,  ...   \n",
       "2   [ Scott Grimes\\n,  Damian Lewis\\n,  Ron Living...   \n",
       "3   [ Bryan Cranston\\n,  Anna Gunn\\n,  Aaron Paul\\...   \n",
       "4   [ Jessie Buckley\\n,  Jared Harris\\n,  Stellan ...   \n",
       "..                                                ...   \n",
       "95  [ Chris Addison\\n,  James Smith\\n,  Peter Capa...   \n",
       "96  [ Natsuki Hanae\\n,  Zach Aguilar\\n,  Abby Trot...   \n",
       "97  [ Sumire Morohoshi\\n,  Maaya Uchida\\n,  Mariya...   \n",
       "98  [ Trey Parker\\n,  Matt Stone\\n,  Mona Marshall...   \n",
       "99  [ Dan Castellaneta\\n,  Nancy Cartwright\\n,  Ha...   \n",
       "\n",
       "                                       Creators     Origin    Language  \\\n",
       "0                                            []       [UK]     English   \n",
       "1                                            []       [UK]     English   \n",
       "2                                            []  [USA, UK]  Lithuanian   \n",
       "3                              [Vince Gilligan]      [USA]     Spanish   \n",
       "4                                 [Craig Mazin]  [USA, UK]     English   \n",
       "..                                          ...        ...         ...   \n",
       "95                                           []       [UK]     English   \n",
       "96                                           []    [Japan]    Japanese   \n",
       "97                                           []    [Japan]    Japanese   \n",
       "98      [Trey Parker, Matt Stone, Brian Graden]      [USA]     English   \n",
       "99  [James L. Brooks, Matt Groening, Sam Simon]      [USA]       Czech   \n",
       "\n",
       "                      Certification Rating  \n",
       "0                                      9.5  \n",
       "1                      Tous publics    9.4  \n",
       "2                      Tous publics    9.4  \n",
       "3                      Tous publics    9.5  \n",
       "4                                12    9.4  \n",
       "..                              ...    ...  \n",
       "95                                     8.7  \n",
       "96  Tous publics avec avertissement    8.8  \n",
       "97                                     8.8  \n",
       "98                               16    8.7  \n",
       "99                     Tous publics    8.7  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_serie = pd.DataFrame(serie_details, \n",
    "                        columns = [\"Rank\", \"Title\", \"Genre\", \"Number_of_season\", \"Number_of_episodes\", \"Type\", \"Actors\", \n",
    "                                   \"Creators\", \"Origin\", \"Language\", \"Certification\", \"Rating\"])\n",
    "\n",
    "df_serie.to_csv('C:\\\\Users\\\\stosc\\\\Documents\\\\ESME\\\\Ingé2_2019-2020\\\\S2\\\\UE1\\\\DataTools\\\\Projet\\series_data.csv', \n",
    "                index=False, header=True)\n",
    "\n",
    "#df_serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the storylines of the TV series as dataframe to analyse them using NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Storyline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Attenborough returns in this breatht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Each 50 minute episode features a global o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the story of \"E\" Easy Company, 506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When chemistry teacher Walter White is dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In April 1986, a huge explosion erupted at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Nathaniel Fisher, his wife Ruth, and their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>From the earliest times, the humanity know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The curious, adventure-seeking, fourth gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>At Grace Field House, life couldn't be bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>This is an animated sitcom about the antic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Storyline\n",
       "1        David Attenborough returns in this breatht...\n",
       "2        Each 50 minute episode features a global o...\n",
       "3        This is the story of \"E\" Easy Company, 506...\n",
       "4        When chemistry teacher Walter White is dia...\n",
       "5        In April 1986, a huge explosion erupted at...\n",
       "..                                                 ...\n",
       "96       Nathaniel Fisher, his wife Ruth, and their...\n",
       "97       From the earliest times, the humanity know...\n",
       "98       The curious, adventure-seeking, fourth gra...\n",
       "99       At Grace Field House, life couldn't be bet...\n",
       "100      This is an animated sitcom about the antic...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storyline = pd.DataFrame(serie_resume, columns=[\"Storyline\"], index=rank)\n",
    "\n",
    "df_storyline.to_csv('C:\\\\Users\\\\stosc\\\\Documents\\\\ESME\\\\Ingé2_2019-2020\\\\S2\\\\UE1\\\\DataTools\\\\Projet\\series_storylines.csv', \n",
    "                header=True)\n",
    "\n",
    "df_storyline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Number_of_season</th>\n",
       "      <th>Number_of_episodes</th>\n",
       "      <th>Type</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Creators</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Language</th>\n",
       "      <th>Certification</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planet Earth II</td>\n",
       "      <td>[' Documentary']</td>\n",
       "      <td>1</td>\n",
       "      <td>6 episodes</td>\n",
       "      <td>TV Mini-Series (2016)\\n</td>\n",
       "      <td>[' David Attenborough\\n']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['UK']</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planète Terre</td>\n",
       "      <td>[' Documentary']</td>\n",
       "      <td>1</td>\n",
       "      <td>11 episodes</td>\n",
       "      <td>TV Mini-Series (2006)\\n</td>\n",
       "      <td>[' David Attenborough\\n', ' Sigourney Weaver\\n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['UK']</td>\n",
       "      <td>English</td>\n",
       "      <td>Tous publics</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Frères d'armes</td>\n",
       "      <td>[' Action', ' Drama', ' History', ' War']</td>\n",
       "      <td>1</td>\n",
       "      <td>10 episodes</td>\n",
       "      <td>TV Mini-Series (2001)\\n</td>\n",
       "      <td>[' Scott Grimes\\n', ' Damian Lewis\\n', ' Ron L...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['USA', 'UK']</td>\n",
       "      <td>Lithuanian</td>\n",
       "      <td>Tous publics</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>[' Crime', ' Drama', ' Thriller']</td>\n",
       "      <td>5</td>\n",
       "      <td>62 episodes</td>\n",
       "      <td>TV Series (2008–2013)\\n</td>\n",
       "      <td>[' Bryan Cranston\\n', ' Anna Gunn\\n', ' Aaron ...</td>\n",
       "      <td>['Vince Gilligan']</td>\n",
       "      <td>['USA']</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Tous publics</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chernobyl</td>\n",
       "      <td>[' Drama', ' History', ' Thriller']</td>\n",
       "      <td>1</td>\n",
       "      <td>5 episodes</td>\n",
       "      <td>TV Mini-Series (2019)\\n</td>\n",
       "      <td>[' Jessie Buckley\\n', ' Jared Harris\\n', ' Ste...</td>\n",
       "      <td>['Craig Mazin']</td>\n",
       "      <td>['USA', 'UK']</td>\n",
       "      <td>English</td>\n",
       "      <td>12</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The Thick of It</td>\n",
       "      <td>[' Comedy']</td>\n",
       "      <td>4</td>\n",
       "      <td>24 episodes</td>\n",
       "      <td>TV Series (2005–2012)\\n</td>\n",
       "      <td>[' Chris Addison\\n', ' James Smith\\n', ' Peter...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['UK']</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Demon Slayer</td>\n",
       "      <td>[' Animation', ' Action', ' Fantasy', ' Thrill...</td>\n",
       "      <td>1</td>\n",
       "      <td>27 episodes</td>\n",
       "      <td>TV Series (2019– )\\n</td>\n",
       "      <td>[' Natsuki Hanae\\n', ' Zach Aguilar\\n', ' Abby...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Japan']</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Tous publics avec avertissement</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Promised Neverland</td>\n",
       "      <td>[' Animation', ' Fantasy', ' Horror', ' Myster...</td>\n",
       "      <td>2</td>\n",
       "      <td>13 episodes</td>\n",
       "      <td>TV Series (2019– )\\n</td>\n",
       "      <td>[' Sumire Morohoshi\\n', ' Maaya Uchida\\n', ' M...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Japan']</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>South Park</td>\n",
       "      <td>[' Animation', ' Comedy']</td>\n",
       "      <td>24</td>\n",
       "      <td>309 episodes</td>\n",
       "      <td>TV Series (1997– )\\n</td>\n",
       "      <td>[' Trey Parker\\n', ' Matt Stone\\n', ' Mona Mar...</td>\n",
       "      <td>['Trey Parker', 'Matt Stone', 'Brian Graden']</td>\n",
       "      <td>['USA']</td>\n",
       "      <td>English</td>\n",
       "      <td>16</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Les Simpson</td>\n",
       "      <td>[' Animation', ' Comedy']</td>\n",
       "      <td>32</td>\n",
       "      <td>684 episodes</td>\n",
       "      <td>TV Series (1989– )\\n</td>\n",
       "      <td>[' Dan Castellaneta\\n', ' Nancy Cartwright\\n',...</td>\n",
       "      <td>['James L. Brooks', 'Matt Groening', 'Sam Simon']</td>\n",
       "      <td>['USA']</td>\n",
       "      <td>Czech</td>\n",
       "      <td>Tous publics</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title  \\\n",
       "Rank                           \n",
       "1            Planet Earth II   \n",
       "2              Planète Terre   \n",
       "3             Frères d'armes   \n",
       "4               Breaking Bad   \n",
       "5                  Chernobyl   \n",
       "...                      ...   \n",
       "96           The Thick of It   \n",
       "97              Demon Slayer   \n",
       "98    The Promised Neverland   \n",
       "99                South Park   \n",
       "100              Les Simpson   \n",
       "\n",
       "                                                  Genre  Number_of_season  \\\n",
       "Rank                                                                        \n",
       "1                                      [' Documentary']                 1   \n",
       "2                                      [' Documentary']                 1   \n",
       "3             [' Action', ' Drama', ' History', ' War']                 1   \n",
       "4                     [' Crime', ' Drama', ' Thriller']                 5   \n",
       "5                   [' Drama', ' History', ' Thriller']                 1   \n",
       "...                                                 ...               ...   \n",
       "96                                          [' Comedy']                 4   \n",
       "97    [' Animation', ' Action', ' Fantasy', ' Thrill...                 1   \n",
       "98    [' Animation', ' Fantasy', ' Horror', ' Myster...                 2   \n",
       "99                            [' Animation', ' Comedy']                24   \n",
       "100                           [' Animation', ' Comedy']                32   \n",
       "\n",
       "     Number_of_episodes                     Type  \\\n",
       "Rank                                               \n",
       "1            6 episodes  TV Mini-Series (2016)\\n   \n",
       "2           11 episodes  TV Mini-Series (2006)\\n   \n",
       "3           10 episodes  TV Mini-Series (2001)\\n   \n",
       "4           62 episodes  TV Series (2008–2013)\\n   \n",
       "5            5 episodes  TV Mini-Series (2019)\\n   \n",
       "...                 ...                      ...   \n",
       "96          24 episodes  TV Series (2005–2012)\\n   \n",
       "97          27 episodes     TV Series (2019– )\\n   \n",
       "98          13 episodes     TV Series (2019– )\\n   \n",
       "99         309 episodes     TV Series (1997– )\\n   \n",
       "100        684 episodes     TV Series (1989– )\\n   \n",
       "\n",
       "                                                 Actors  \\\n",
       "Rank                                                      \n",
       "1                             [' David Attenborough\\n']   \n",
       "2     [' David Attenborough\\n', ' Sigourney Weaver\\n...   \n",
       "3     [' Scott Grimes\\n', ' Damian Lewis\\n', ' Ron L...   \n",
       "4     [' Bryan Cranston\\n', ' Anna Gunn\\n', ' Aaron ...   \n",
       "5     [' Jessie Buckley\\n', ' Jared Harris\\n', ' Ste...   \n",
       "...                                                 ...   \n",
       "96    [' Chris Addison\\n', ' James Smith\\n', ' Peter...   \n",
       "97    [' Natsuki Hanae\\n', ' Zach Aguilar\\n', ' Abby...   \n",
       "98    [' Sumire Morohoshi\\n', ' Maaya Uchida\\n', ' M...   \n",
       "99    [' Trey Parker\\n', ' Matt Stone\\n', ' Mona Mar...   \n",
       "100   [' Dan Castellaneta\\n', ' Nancy Cartwright\\n',...   \n",
       "\n",
       "                                               Creators         Origin  \\\n",
       "Rank                                                                     \n",
       "1                                                    []         ['UK']   \n",
       "2                                                    []         ['UK']   \n",
       "3                                                    []  ['USA', 'UK']   \n",
       "4                                    ['Vince Gilligan']        ['USA']   \n",
       "5                                       ['Craig Mazin']  ['USA', 'UK']   \n",
       "...                                                 ...            ...   \n",
       "96                                                   []         ['UK']   \n",
       "97                                                   []      ['Japan']   \n",
       "98                                                   []      ['Japan']   \n",
       "99        ['Trey Parker', 'Matt Stone', 'Brian Graden']        ['USA']   \n",
       "100   ['James L. Brooks', 'Matt Groening', 'Sam Simon']        ['USA']   \n",
       "\n",
       "        Language                    Certification  Rating  \n",
       "Rank                                                       \n",
       "1        English                              NaN     9.5  \n",
       "2        English                     Tous publics     9.4  \n",
       "3     Lithuanian                     Tous publics     9.4  \n",
       "4        Spanish                     Tous publics     9.5  \n",
       "5        English                               12     9.4  \n",
       "...          ...                              ...     ...  \n",
       "96       English                              NaN     8.7  \n",
       "97      Japanese  Tous publics avec avertissement     8.8  \n",
       "98      Japanese                              NaN     8.8  \n",
       "99       English                               16     8.7  \n",
       "100        Czech                     Tous publics     8.7  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file into a dataframe.\n",
    "df_serie = pd.read_csv(\"C:\\\\Users\\\\stosc\\\\Documents\\\\ESME\\\\Ingé2_2019-2020\\\\S2\\\\UE1\\\\DataTools\\\\Projet\\series_data.csv\",\n",
    "                      header=0, index_col=0)\n",
    "\n",
    "df_serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_storylines = pd.read_csv(\"C:\\\\Users\\\\stosc\\\\Documents\\\\ESME\\\\Ingé2_2019-2020\\\\S2\\\\UE1\\\\DataTools\\\\Projet\\series_storylines.csv\",\n",
    "                      #header=0, index_col=0)\n",
    "\n",
    "df_storylines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
